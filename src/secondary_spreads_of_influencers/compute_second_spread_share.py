#!/usr/bin/env python3

import os
import argparse
import polars as pl
import matplotlib as mpl
mpl.use("WebAgg")
mpl.rc("webagg", port=8899, port_retries=10, open_in_browser=False)
import matplotlib.pyplot as plt
import seaborn as sns
import scienceplots


arg_parser = argparse.ArgumentParser()
arg_parser.add_argument("--retweeted_tweets_dir", type=str, required=True)
arg_parser.add_argument("--aggregated_second_sperads", type=str, required=True)
arg_parser.add_argument("--user_influence_score_path", type=str, required=True)
arg_parser.add_argument("--influence_column_name", type=str, default="hg-index")
arg_parser.add_argument("--output_result_file", type=str, required=True)
arg_parser.add_argument("--is_in_cascade", action="store_true")
arg_parser.add_argument("--exclude_official", action="store_true")
arg_parser.add_argument("--min_rt", type=int, default=0)


# [File Summary]
# This script plots the second spread share by user influence score.
# [Configs]
# influence_column_name:
#   The column name of the user influence score.
# is_in_cascade:
#   If True, only include the second spreaders in the cascade.
# exclude_official:
#   If True, exclude the official accounts from the analysis.
# min_rt:
#   The minimum number of retweets to be considered.
# [Inputs]
# retweeted_tweets_dir:
#   Directory path where the retweeted tweets are stored.
# aggregated_second_sperads:
#   Path to the aggregated second spreaders.
#   This file is generated by aggregate_second_spreads.py.
# user_influence_score_path:
#   Path to the user influence score.
#   This file is generated by compute_h_index.py or compute_centrality_from_retweets.py.


def main(args):
    print("Loading retweeted tweets...")
    retweeted_tweets_files = os.listdir(args.retweeted_tweets_dir)
    retweeted_tweets_paths = [os.path.join(args.retweeted_tweets_dir, f)
                              for f in retweeted_tweets_files]

    df_list = []
    for i, path in enumerate(retweeted_tweets_paths):
        df_rt = pl.read_parquet(path)
        df_list.append(df_rt)
    df_rt = pl.concat(df_list)
    del df_list
    df_rt = df_rt.filter(df_rt["user_id"].is_not_null())
    df_rt = df_rt[["source_tweet_id", "user_id", "tweet_id"]]
    df_rt = df_rt.filter(df_rt["source_tweet_id"].is_not_null())
    df_rt = df_rt.group_by("source_tweet_id").agg(
        pl.col("user_id").n_unique().alias("num_retweets")
    )

    target_source_tweet_ids = df_rt.filter(
        pl.col("num_retweets") > args.min_rt)["source_tweet_id"].to_list()

    print("Loading Second Spreads...")
    df_ss = pl.read_parquet(args.aggregated_second_sperads)

    if args.is_in_cascade:
        df_ss = df_ss.filter(pl.col("is_in_cascade"))

    if args.exclude_official:
        df_ss = df_ss.filter(~pl.col("is_official"))

    df_ss = df_ss.filter(pl.col("source_tweet_id").is_in(target_source_tweet_ids))

    df_user_influence = pl.read_parquet(args.user_influence_score_path)
    df_user_influence = df_user_influence.with_columns(
        pl.col(args.influence_column_name).rank("min").alias("rank"))
    df_user_influence = df_user_influence.with_columns(
        pl.col(args.influence_column_name).qcut(
            [0.5, 0.7, 0.9, 0.95, 0.99],
            labels=["low", "low-mid", "mid", "high-mid", "high", "very-high"],
            allow_duplicates=True,
        ).alias("influence_score_group"))

    df_ss = df_ss.join(
        df_user_influence,
        left_on="followee",
        right_on="user_id",
        coalesce=True)

    df_result = df_ss.group_by("influence_score_group").agg(
        pl.col("followee").n_unique().alias("num_followees"),
        pl.sum("num_views").alias("num_views"),
        pl.sum("num_retweets").alias("num_retweets"),
    )

    df_result = df_result.sort("influence_score_group", descending=True)
    df_result.write_excel(args.output_result_file)

    cmap = sns.diverging_palette(220, 20)

    df_result = df_result.with_columns(
        pl.Series(reversed([cmap[i] for i in range(df_result.shape[0])])).alias("color"))

    fig, ax = plt.subplots(1, 2, figsize=(12, 5))

    _, texts, autotexts = ax[0].pie(
        df_result.sort("num_views", descending=True).to_pandas()["num_views"],
        labels=df_result.sort("num_views", descending=True).to_pandas()["influence_score_group"],
        colors=df_result.sort("num_views", descending=True).to_pandas()["color"],
        autopct=lambda p: "{:.1f}%".format(p) if p > 5.5 else "",
        startangle=90,
        counterclock=False,
    )
    for t in texts:
        t.set_fontsize(12)
    for t in autotexts:
        t.set_fontsize(12)

    _, texts, autotexts = ax[1].pie(
        df_result.sort("num_retweets", descending=True).to_pandas()["num_retweets"],
        labels=df_result.sort("num_retweets", descending=True).to_pandas()["influence_score_group"],
        colors=df_result.sort("num_retweets", descending=True).to_pandas()["color"],
        autopct=lambda p: "{:.1f}%".format(p) if p > 5.2 else "",
        startangle=90,
        counterclock=False,
    )
    for t in texts:
        t.set_fontsize(12)
    for t in autotexts:
        t.set_fontsize(12)

    plt.show()


if __name__ == "__main__":
    args = arg_parser.parse_args()
    main(args)
